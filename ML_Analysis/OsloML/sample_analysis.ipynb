{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib\n",
    "#matplotlib.rcParams.update({'font.size': 20})\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bkg0 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/training_bkg_2L_pt25_25_met50_0.h5\")\n",
    "train_bkg1 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/training_bkg_2L_pt25_25_met50_1.h5\")\n",
    "train_bkg2 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/training_bkg_2L_pt25_25_met50_2.h5\")\n",
    "train_bkg3 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/training_bkg_2L_pt25_25_met50_3.h5\")\n",
    "train_bkg5 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/training_bkg_2L_pt25_25_met50_5.h5\")\n",
    "train_bkg7 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/training_bkg_2L_pt25_25_met50_7.h5\")\n",
    "train_bkg8 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/training_bkg_2L_pt25_25_met50_8.h5\")\n",
    "train_bkg9 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/training_bkg_2L_pt25_25_met50_9.h5\")\n",
    "\n",
    "test_bkg0 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/testing_bkg_2L_pt25_25_met50_0.h5\")\n",
    "test_bkg1 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/testing_bkg_2L_pt25_25_met50_1.h5\")\n",
    "test_bkg2 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/testing_bkg_2L_pt25_25_met50_2.h5\")\n",
    "test_bkg3 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/testing_bkg_2L_pt25_25_met50_3.h5\")\n",
    "test_bkg5 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/testing_bkg_2L_pt25_25_met50_5.h5\")\n",
    "test_bkg7 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/testing_bkg_2L_pt25_25_met50_7.h5\")\n",
    "test_bkg8 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/testing_bkg_2L_pt25_25_met50_8.h5\")\n",
    "test_bkg9 = pd.read_hdf(\"/home/michael/Desktop/OpenData/SM_Backgrounds/testing_bkg_2L_pt25_25_met50_9.h5\")\n",
    "\n",
    "train_sig0 = pd.read_hdf(\"/home/michael/Desktop/OpenData/BSM_Signal_Samples/BSM_Signal_Samples/training_sig_2L_pt25_25_met50_0.h5\")\n",
    "train_sig1 = pd.read_hdf(\"/home/michael/Desktop/OpenData/BSM_Signal_Samples/BSM_Signal_Samples/training_sig_2L_pt25_25_met50_1.h5\")\n",
    "\n",
    "test_sig0 = pd.read_hdf(\"/home/michael/Desktop/OpenData/BSM_Signal_Samples/BSM_Signal_Samples/testing_sig_2L_pt25_25_met50_0.h5\")\n",
    "test_sig1 = pd.read_hdf(\"/home/michael/Desktop/OpenData/BSM_Signal_Samples/BSM_Signal_Samples/testing_sig_2L_pt25_25_met50_1.h5\")\n",
    "\n",
    "frames_train = [train_bkg0,train_bkg1,train_bkg2,train_bkg3,train_bkg5,train_bkg7,train_bkg8,train_bkg9,train_sig0,train_sig1]\n",
    "frames_test = [test_bkg0,test_bkg1,test_bkg2,test_bkg3,test_bkg5,test_bkg7,test_bkg8,test_bkg9,test_sig0,test_sig1]\n",
    "merged_train = pd.concat(frames_train)\n",
    "merged_test = pd.concat(frames_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "merged_train = shuffle(merged_train)\n",
    "merged_test = shuffle(merged_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = merged_train[['met_et','mll','met_phi']]\n",
    "Y_train = merged_train['isSignal']\n",
    "X_test = merged_test[['met_et','mll','met_phi']]\n",
    "Y_test = merged_test['isSignal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BDT classifier\n",
    "xgbclassifier = xgb.XGBClassifier(\n",
    "    max_depth=3, \n",
    "    n_estimators=120,\n",
    "    learning_rate=0.1,\n",
    "    n_jobs=4,\n",
    "    #scale_pos_weight=sum_wbkg/sum_wsig,\n",
    "    objective='binary:logistic')\n",
    "    #missing=-999.0) \n",
    "xgbclassifier.fit(X_train, Y_train) \n",
    "# Plot variable importance\n",
    "fig_size = plt.rcParams[\"figure.figsize\"] \n",
    "xgb.plot_importance(xgbclassifier)\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 15\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.show()\n",
    "y_pred = xgbclassifier.predict(X_test)\n",
    "y_pred_prob = xgbclassifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGREG classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_pred_prob = logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  histogram of the ML outputs\n",
    "n, bins, patches = plt.hist(y_pred_prob[:,1][Y_test==0], 100, normed=0, facecolor='blue', alpha=0.2,label=\"Background\")\n",
    "n, bins, patches = plt.hist(y_pred_prob[:,1][Y_test==1], 100, normed=0, facecolor='red', alpha=0.2, label=\"Signal\")\n",
    "plt.xlabel('ML output')\n",
    "plt.ylabel('Events')\n",
    "plt.yscale('log')\n",
    "plt.title('ML output, OpenData dataset, validation data')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "fpr, tpr, thresholds = roc_curve(Y_test,y_pred_prob[:,1], pos_label=1)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC on OpenData dataset')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(Y_test, y_pred, ['background','signal'], normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0\n",
    "h_true_bkg = []\n",
    "h_true_sig = []\n",
    "for q in Y_test:\n",
    "    if q == 0:\n",
    "        h_true_bkg.append((X_test['mll'].iloc[m]))\n",
    "    else:    \n",
    "        h_true_sig.append((X_test['mll'].iloc[m]))\n",
    "    m += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0\n",
    "h_pred_bkg = []\n",
    "h_pred_sig = []\n",
    "for q in y_pred:\n",
    "    if q == 0:\n",
    "        h_pred_bkg.append((X_test['mll'].iloc[m]))\n",
    "    else:    \n",
    "        h_pred_sig.append((X_test['mll'].iloc[m]))\n",
    "    m += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(h_true_sig,bins=100,log=True)\n",
    "plt.hist(h_pred_sig,bins=100,log=True)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(h_true_bkg,bins=100,log=True)\n",
    "plt.hist(h_pred_bkg,bins=100,log=True)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
